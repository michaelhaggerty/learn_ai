{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.6.tar.gz (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /Users/michael/anaconda3/envs/ta-lib/lib/python3.9/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /Users/michael/anaconda3/envs/ta-lib/lib/python3.9/site-packages (from kaggle) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil in /Users/michael/anaconda3/envs/ta-lib/lib/python3.9/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /Users/michael/anaconda3/envs/ta-lib/lib/python3.9/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/michael/anaconda3/envs/ta-lib/lib/python3.9/site-packages (from kaggle) (4.64.1)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: urllib3 in /Users/michael/anaconda3/envs/ta-lib/lib/python3.9/site-packages (from kaggle) (1.26.15)\n",
      "Requirement already satisfied: bleach in /Users/michael/anaconda3/envs/ta-lib/lib/python3.9/site-packages (from kaggle) (6.0.0)\n",
      "Requirement already satisfied: webencodings in /Users/michael/anaconda3/envs/ta-lib/lib/python3.9/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Users/michael/anaconda3/envs/ta-lib/lib/python3.9/site-packages (from requests->kaggle) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/michael/anaconda3/envs/ta-lib/lib/python3.9/site-packages (from requests->kaggle) (2.10)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.6-py3-none-any.whl size=111945 sha256=e39eb45139416b43f100fbcc7ccccb5254f6c8afbc06784a681bc802724fcc6f\n",
      "  Stored in directory: /Users/michael/Library/Caches/pip/wheels/46/aa/c3/b3e421522fb5acdd7c366a05c5fc80787615bdeed207e7f79b\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.6.6 python-slugify-8.0.4 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Kaggle API credentials from ~/.kaggle/kaggle.json\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Ensure you replace '/Users/michael/.kaggle/kaggle.json' with your actual path if different\n",
    "with open('/Users/michael/.kaggle/kaggle.json') as f:\n",
    "    kaggle_credentials = json.load(f)\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_credentials['username']\n",
    "os.environ['KAGGLE_KEY'] = kaggle_credentials['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions list --csv > Datasets/competitions.csv\n",
    "\n",
    "# Now, read the CSV file into a pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "competitions_df = pd.read_csv('Datasets/competitions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Warning: Looks like you're using an outdated API Version</th>\n",
       "      <th>please consider updating (server 1.6.7 / client 1.6.6)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ref</th>\n",
       "      <th>deadline</th>\n",
       "      <th>category</th>\n",
       "      <th>reward</th>\n",
       "      <td>teamCount</td>\n",
       "      <td>userHasEntered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/llm-prompt-recovery</th>\n",
       "      <th>2024-04-16 23:59:00</th>\n",
       "      <th>Featured</th>\n",
       "      <th>$200,000</th>\n",
       "      <td>167</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data</th>\n",
       "      <th>2024-04-23 23:59:00</th>\n",
       "      <th>Featured</th>\n",
       "      <th>$60,000</th>\n",
       "      <td>1238</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification</th>\n",
       "      <th>2024-04-08 23:59:00</th>\n",
       "      <th>Research</th>\n",
       "      <th>$50,000</th>\n",
       "      <td>1984</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/march-machine-learning-mania-2024</th>\n",
       "      <th>2024-04-10 23:59:00</th>\n",
       "      <th>Featured</th>\n",
       "      <th>$50,000</th>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/data-assistants-with-gemma</th>\n",
       "      <th>2024-04-14 23:59:00</th>\n",
       "      <th>Analytics</th>\n",
       "      <th>$50,000</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/playground-series-s4e2</th>\n",
       "      <th>2024-02-29 23:59:00</th>\n",
       "      <th>Playground</th>\n",
       "      <th>Swag</th>\n",
       "      <td>3557</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/planttraits2024</th>\n",
       "      <th>2024-06-15 22:00:00</th>\n",
       "      <th>Research</th>\n",
       "      <th>Knowledge</th>\n",
       "      <td>113</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/titanic</th>\n",
       "      <th>2030-01-01 00:00:00</th>\n",
       "      <th>Getting Started</th>\n",
       "      <th>Knowledge</th>\n",
       "      <td>15479</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques</th>\n",
       "      <th>2030-01-01 00:00:00</th>\n",
       "      <th>Getting Started</th>\n",
       "      <th>Knowledge</th>\n",
       "      <td>4001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/spaceship-titanic</th>\n",
       "      <th>2030-01-01 00:00:00</th>\n",
       "      <th>Getting Started</th>\n",
       "      <th>Knowledge</th>\n",
       "      <td>2623</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/digit-recognizer</th>\n",
       "      <th>2030-01-01 00:00:00</th>\n",
       "      <th>Getting Started</th>\n",
       "      <th>Knowledge</th>\n",
       "      <td>1599</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/nlp-getting-started</th>\n",
       "      <th>2030-01-01 00:00:00</th>\n",
       "      <th>Getting Started</th>\n",
       "      <th>Knowledge</th>\n",
       "      <td>867</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/connectx</th>\n",
       "      <th>2030-01-01 00:00:00</th>\n",
       "      <th>Getting Started</th>\n",
       "      <th>Knowledge</th>\n",
       "      <td>213</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/tpu-getting-started</th>\n",
       "      <th>2030-06-03 23:59:00</th>\n",
       "      <th>Getting Started</th>\n",
       "      <th>Knowledge</th>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/store-sales-time-series-forecasting</th>\n",
       "      <th>2030-06-30 23:59:00</th>\n",
       "      <th>Getting Started</th>\n",
       "      <th>Knowledge</th>\n",
       "      <td>682</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/gan-getting-started</th>\n",
       "      <th>2030-07-01 23:59:00</th>\n",
       "      <th>Getting Started</th>\n",
       "      <th>Knowledge</th>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/contradictory-my-dear-watson</th>\n",
       "      <th>2030-07-01 23:59:00</th>\n",
       "      <th>Getting Started</th>\n",
       "      <th>Knowledge</th>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability</th>\n",
       "      <th>2024-05-06 23:59:00</th>\n",
       "      <th>Featured</th>\n",
       "      <th>$105,000</th>\n",
       "      <td>1186</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/optiver-trading-at-the-close</th>\n",
       "      <th>2024-03-20 23:59:00</th>\n",
       "      <th>Featured</th>\n",
       "      <th>$100,000</th>\n",
       "      <td>4436</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.kaggle.com/competitions/predict-energy-behavior-of-prosumers</th>\n",
       "      <th>2024-04-30 23:59:00</th>\n",
       "      <th>Featured</th>\n",
       "      <th>$50,000</th>\n",
       "      <td>2731</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 Warning: Looks like you're using an outdated API Version  \\\n",
       "ref                                                deadline            category        reward                                             teamCount         \n",
       "https://www.kaggle.com/competitions/llm-prompt-... 2024-04-16 23:59:00 Featured        $200,000                                                 167         \n",
       "https://www.kaggle.com/competitions/pii-detecti... 2024-04-23 23:59:00 Featured        $60,000                                                 1238         \n",
       "https://www.kaggle.com/competitions/hms-harmful... 2024-04-08 23:59:00 Research        $50,000                                                 1984         \n",
       "https://www.kaggle.com/competitions/march-machi... 2024-04-10 23:59:00 Featured        $50,000                                                   24         \n",
       "https://www.kaggle.com/competitions/data-assist... 2024-04-14 23:59:00 Analytics       $50,000                                                    0         \n",
       "https://www.kaggle.com/competitions/playground-... 2024-02-29 23:59:00 Playground      Swag                                                    3557         \n",
       "https://www.kaggle.com/competitions/planttraits... 2024-06-15 22:00:00 Research        Knowledge                                                113         \n",
       "https://www.kaggle.com/competitions/titanic        2030-01-01 00:00:00 Getting Started Knowledge                                              15479         \n",
       "https://www.kaggle.com/competitions/house-price... 2030-01-01 00:00:00 Getting Started Knowledge                                               4001         \n",
       "https://www.kaggle.com/competitions/spaceship-t... 2030-01-01 00:00:00 Getting Started Knowledge                                               2623         \n",
       "https://www.kaggle.com/competitions/digit-recog... 2030-01-01 00:00:00 Getting Started Knowledge                                               1599         \n",
       "https://www.kaggle.com/competitions/nlp-getting... 2030-01-01 00:00:00 Getting Started Knowledge                                                867         \n",
       "https://www.kaggle.com/competitions/connectx       2030-01-01 00:00:00 Getting Started Knowledge                                                213         \n",
       "https://www.kaggle.com/competitions/tpu-getting... 2030-06-03 23:59:00 Getting Started Knowledge                                                 58         \n",
       "https://www.kaggle.com/competitions/store-sales... 2030-06-30 23:59:00 Getting Started Knowledge                                                682         \n",
       "https://www.kaggle.com/competitions/gan-getting... 2030-07-01 23:59:00 Getting Started Knowledge                                                 77         \n",
       "https://www.kaggle.com/competitions/contradicto... 2030-07-01 23:59:00 Getting Started Knowledge                                                 46         \n",
       "https://www.kaggle.com/competitions/home-credit... 2024-05-06 23:59:00 Featured        $105,000                                                1186         \n",
       "https://www.kaggle.com/competitions/optiver-tra... 2024-03-20 23:59:00 Featured        $100,000                                                4436         \n",
       "https://www.kaggle.com/competitions/predict-ene... 2024-04-30 23:59:00 Featured        $50,000                                                 2731         \n",
       "\n",
       "                                                                                                  please consider updating (server 1.6.7 / client 1.6.6)  \n",
       "ref                                                deadline            category        reward                                        userHasEntered       \n",
       "https://www.kaggle.com/competitions/llm-prompt-... 2024-04-16 23:59:00 Featured        $200,000                                               False       \n",
       "https://www.kaggle.com/competitions/pii-detecti... 2024-04-23 23:59:00 Featured        $60,000                                                False       \n",
       "https://www.kaggle.com/competitions/hms-harmful... 2024-04-08 23:59:00 Research        $50,000                                                False       \n",
       "https://www.kaggle.com/competitions/march-machi... 2024-04-10 23:59:00 Featured        $50,000                                                False       \n",
       "https://www.kaggle.com/competitions/data-assist... 2024-04-14 23:59:00 Analytics       $50,000                                                False       \n",
       "https://www.kaggle.com/competitions/playground-... 2024-02-29 23:59:00 Playground      Swag                                                   False       \n",
       "https://www.kaggle.com/competitions/planttraits... 2024-06-15 22:00:00 Research        Knowledge                                              False       \n",
       "https://www.kaggle.com/competitions/titanic        2030-01-01 00:00:00 Getting Started Knowledge                                              False       \n",
       "https://www.kaggle.com/competitions/house-price... 2030-01-01 00:00:00 Getting Started Knowledge                                              False       \n",
       "https://www.kaggle.com/competitions/spaceship-t... 2030-01-01 00:00:00 Getting Started Knowledge                                              False       \n",
       "https://www.kaggle.com/competitions/digit-recog... 2030-01-01 00:00:00 Getting Started Knowledge                                              False       \n",
       "https://www.kaggle.com/competitions/nlp-getting... 2030-01-01 00:00:00 Getting Started Knowledge                                              False       \n",
       "https://www.kaggle.com/competitions/connectx       2030-01-01 00:00:00 Getting Started Knowledge                                              False       \n",
       "https://www.kaggle.com/competitions/tpu-getting... 2030-06-03 23:59:00 Getting Started Knowledge                                              False       \n",
       "https://www.kaggle.com/competitions/store-sales... 2030-06-30 23:59:00 Getting Started Knowledge                                              False       \n",
       "https://www.kaggle.com/competitions/gan-getting... 2030-07-01 23:59:00 Getting Started Knowledge                                              False       \n",
       "https://www.kaggle.com/competitions/contradicto... 2030-07-01 23:59:00 Getting Started Knowledge                                              False       \n",
       "https://www.kaggle.com/competitions/home-credit... 2024-05-06 23:59:00 Featured        $105,000                                               False       \n",
       "https://www.kaggle.com/competitions/optiver-tra... 2024-03-20 23:59:00 Featured        $100,000                                                True       \n",
       "https://www.kaggle.com/competitions/predict-ene... 2024-04-30 23:59:00 Featured        $50,000                                                False       "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "competitions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get a dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vehicle-sales-data.zip to Datasets\n",
      "100%|██████████████████████████████████████| 18.8M/18.8M [00:05<00:00, 3.59MB/s]\n",
      "100%|██████████████████████████████████████| 18.8M/18.8M [00:05<00:00, 3.57MB/s]\n",
      "Archive:  Datasets/vehicle-sales-data.zip\n",
      "  inflating: Datasets/car_prices.csv  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Download the dataset\n",
    "!kaggle datasets download -d syedanwarafridi/vehicle-sales-data -p Datasets/\n",
    "\n",
    "# Step 2: Unzip the dataset\n",
    "!unzip -o Datasets/vehicle-sales-data.zip -d Datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Datasets/car_prices.csv')\n",
    "\n",
    "# Convert 'saledate' to datetime format, ignoring errors\n",
    "df['saledate'] = pd.to_datetime(df['saledate'], errors='coerce')\n",
    "\n",
    "# Filter out rows where 'saledate' is NaT (not a time) to avoid the TypeError\n",
    "valid_dates_df = df.dropna(subset=['saledate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real life problem solving to get time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "year 16500 is out of range: 16500 present at position 2896",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/dateutil/parser/_parser.py:649\u001b[0m, in \u001b[0;36mparser.parse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 649\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/dateutil/parser/_parser.py:1235\u001b[0m, in \u001b[0;36mparser._build_naive\u001b[0;34m(self, res, default)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         repl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m monthrange(cyear, cmonth)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1235\u001b[0m naive \u001b[38;5;241m=\u001b[39m \u001b[43mdefault\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrepl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mweekday \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res\u001b[38;5;241m.\u001b[39mday:\n",
      "\u001b[0;31mValueError\u001b[0m: year 16500 is out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:605\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/_libs/tslibs/parsing.pyx:318\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/dateutil/parser/_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULTPARSER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/dateutil/parser/_parser.py:651\u001b[0m, in \u001b[0;36mparser.parse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 651\u001b[0m     \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParserError\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignoretz:\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: year 16500 is out of range: 16500",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:616\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid string coercion to datetime for \"16500\" at position 2896",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/dateutil/parser/_parser.py:649\u001b[0m, in \u001b[0;36mparser.parse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 649\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_naive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/dateutil/parser/_parser.py:1235\u001b[0m, in \u001b[0;36mparser._build_naive\u001b[0;34m(self, res, default)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         repl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m monthrange(cyear, cmonth)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m-> 1235\u001b[0m naive \u001b[38;5;241m=\u001b[39m \u001b[43mdefault\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrepl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mweekday \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res\u001b[38;5;241m.\u001b[39mday:\n",
      "\u001b[0;31mValueError\u001b[0m: year 16500 is out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# let's look at date range\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# first we need datetimee object\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaledate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaledate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:1064\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(tz)\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1064\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1066\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:229\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    227\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[0;32m--> 229\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/core/tools/datetimes.py:438\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_datetime_format\n\u001b[1;32m    437\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 438\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[1;32m    451\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2175\u001b[0m order: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flags\u001b[38;5;241m.\u001b[39mf_contiguous \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2177\u001b[0m     result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2179\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2182\u001b[0m \u001b[43m        \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_mixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_mixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2186\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m   2187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   2188\u001b[0m     \u001b[38;5;66;03m# Exception is raised when a part of date is greater than 32 bit signed int\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:427\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:683\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:829\u001b[0m, in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/_libs/tslib.pyx:819\u001b[0m, in \u001b[0;36mpandas._libs.tslib._array_to_datetime_object\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/_libs/tslibs/parsing.pyx:318\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/dateutil/parser/_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser(parserinfo)\u001b[38;5;241m.\u001b[39mparse(timestr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULTPARSER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/dateutil/parser/_parser.py:651\u001b[0m, in \u001b[0;36mparser.parse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_naive(res, default)\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 651\u001b[0m     \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParserError\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignoretz:\n\u001b[1;32m    654\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_tzaware(ret, res, tzinfos)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: year 16500 is out of range: 16500 present at position 2896"
     ]
    }
   ],
   "source": [
    "# let's look at date range\n",
    "\n",
    "# first we need datetimee object\n",
    "df['saledate'] = pd.to_datetime(df['saledate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558837\n",
      "Earliest sale date: NaT\n",
      "Latest sale date: NaT\n"
     ]
    }
   ],
   "source": [
    "# Attempt to parse dates ignoring the timezone information\n",
    "df['saledate'] = pd.to_datetime(df['saledate'], errors='coerce', format='%a %b %d %Y %H:%M:%S')\n",
    "\n",
    "# Check the conversion, if there are 'NaT' values, those were failed conversions\n",
    "print(df['saledate'].isnull().sum())\n",
    "\n",
    "# Now find the date range\n",
    "earliest_date = df['saledate'].min()\n",
    "latest_date = df['saledate'].max()\n",
    "\n",
    "print(f\"Earliest sale date: {earliest_date}\")\n",
    "print(f\"Latest sale date: {latest_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Remove timezone information from the 'saledate' strings\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaledate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaledate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGMT-\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{4}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m([A-Z]\u001b[39m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Now try converting to datetime without specifying a format\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaledate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaledate\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/core/accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 182\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/core/strings/accessor.py:181\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m is_categorical_dtype(data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/core/strings/accessor.py:235\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    232\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# Remove timezone information from the 'saledate' strings\n",
    "df['saledate'] = df['saledate'].str.replace(r'GMT-\\d{4} \\([A-Z]{3}\\)', '', regex=True)\n",
    "\n",
    "# Now try converting to datetime without specifying a format\n",
    "df['saledate'] = pd.to_datetime(df['saledate'], errors='coerce')\n",
    "\n",
    "# Check the conversion again\n",
    "earliest_date = df['saledate'].min()\n",
    "latest_date = df['saledate'].max()\n",
    "\n",
    "print(f\"Earliest sale date: {earliest_date}\")\n",
    "print(f\"Latest sale date: {latest_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2014, 1, 1, 9, 15, tzinfo=tzoffset('PST', 28800)),\n",
       " datetime.datetime(2015, 7, 21, 2, 30, tzinfo=tzoffset('PDT', 25200)))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, find the earliest and latest date in the 'saledate' column of the filtered DataFrame\n",
    "earliest_date_valid = valid_dates_df['saledate'].min()\n",
    "latest_date_valid = valid_dates_df['saledate'].max()\n",
    "\n",
    "earliest_date_valid, latest_date_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-01-2014\n",
      "07-21-2015\n"
     ]
    }
   ],
   "source": [
    "# Assuming valid_dates_df['saledate'] contains datetime objects\n",
    "earliest_date_valid = valid_dates_df['saledate'].min().strftime('%m-%d-%Y')\n",
    "latest_date_valid = valid_dates_df['saledate'].max().strftime('%m-%d-%Y')\n",
    "\n",
    "print(earliest_date_valid)\n",
    "print(latest_date_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson - The Problem:\n",
    "\n",
    "Your 'saledate' column contains timezone-aware datetime objects (notice the \"+07:00\" at the end of your sample values). Pandas generally prefers working with naive datetimes (without timezone info) by default. To convert these timezone-aware datetimes, you need to specify how to handle the timezones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'saledate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'saledate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Convert to UTC: This is useful if all your dates should be treated as being in UTC.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaledate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaledate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m, utc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 2. Convert to a Specific Timezone: Replace 'US/Pacific' with the appropriate timezone for your data.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#df['saledate'] = pd.to_datetime(df['saledate'], format='%Y-%m-%d %H:%M:%S%z').dt.tz_localize('US/Pacific')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 3. Remove Timezone Information: Use this if the timezone information is not relevant to your analysis.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaledate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaledate\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:S\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'saledate'"
     ]
    }
   ],
   "source": [
    "# 1. Convert to UTC: This is useful if all your dates should be treated as being in UTC.\n",
    "df['saledate'] = pd.to_datetime(df['saledate'], format='%Y-%m-%d %H:%M:%S%z', utc=True) \n",
    "# 2. Convert to a Specific Timezone: Replace 'US/Pacific' with the appropriate timezone for your data.\n",
    "#df['saledate'] = pd.to_datetime(df['saledate'], format='%Y-%m-%d %H:%M:%S%z').dt.tz_localize('US/Pacific')\n",
    "# 3. Remove Timezone Information: Use this if the timezone information is not relevant to your analysis.\n",
    "df['saledate'] = pd.to_datetime(df['saledate'], format = '%Y-%m-%d %H:%M:S%z').dt.tz_localize(None)\n",
    "# 4. We can also create a simplified column with just the date\n",
    "df['date'] = df['saledate'].dt.strftime('%m-%d-%Y')\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 558799 entries, 2015-05-27 to 2015-04-02\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   year          558799 non-null  int64  \n",
      " 1   make          548498 non-null  object \n",
      " 2   model         548400 non-null  object \n",
      " 3   trim          548148 non-null  object \n",
      " 4   body          545604 non-null  object \n",
      " 5   transmission  493448 non-null  object \n",
      " 6   vin           558799 non-null  object \n",
      " 7   state         558799 non-null  object \n",
      " 8   condition     547005 non-null  float64\n",
      " 9   odometer      558705 non-null  float64\n",
      " 10  color         558050 non-null  object \n",
      " 11  interior      558050 non-null  object \n",
      " 12  seller        558799 non-null  object \n",
      " 13  mmr           558799 non-null  int64  \n",
      " 14  sellingprice  558799 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(10)\n",
      "memory usage: 68.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year            100.000000\n",
      "make             98.156582\n",
      "model            98.139045\n",
      "trim             98.093948\n",
      "body             97.638686\n",
      "transmission     88.305097\n",
      "vin             100.000000\n",
      "state           100.000000\n",
      "condition        97.889402\n",
      "odometer         99.983178\n",
      "color            99.865963\n",
      "interior         99.865963\n",
      "seller          100.000000\n",
      "mmr             100.000000\n",
      "sellingprice    100.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#  let's see how much of the data is \"viable\"\n",
    "import pandas as pd\n",
    "\n",
    "def percentage_viable(df):\n",
    "    \"\"\"Calculates the percentage of viable (not null) values in each column.\n",
    "    \"\"\"\n",
    "    viable_counts = df.notnull().sum()\n",
    "    total_counts = df.shape[0]  # Number of rows\n",
    "    return (viable_counts / total_counts) * 100\n",
    "\n",
    "result = percentage_viable(df)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 558799 entries, 2015-05-27 to 2015-04-02\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   year          558799 non-null  int64  \n",
      " 1   make          548498 non-null  object \n",
      " 2   model         548400 non-null  object \n",
      " 3   trim          548148 non-null  object \n",
      " 4   body          545604 non-null  object \n",
      " 5   transmission  493448 non-null  object \n",
      " 6   vin           558799 non-null  object \n",
      " 7   state         558799 non-null  object \n",
      " 8   condition     547005 non-null  float64\n",
      " 9   odometer      558705 non-null  float64\n",
      " 10  color         558050 non-null  object \n",
      " 11  interior      558050 non-null  object \n",
      " 12  seller        558799 non-null  object \n",
      " 13  mmr           558799 non-null  int64  \n",
      " 14  sellingprice  558799 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(10)\n",
      "memory usage: 68.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Sales over time - Example\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[1;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msellingprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mplot()  \u001b[38;5;66;03m# Monthly sales\u001b[39;00m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ta-lib/lib/python3.9/site-packages/pandas/core/frame.py:6012\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6009\u001b[0m                 missing\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[1;32m   6011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m-> 6012\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are in the columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   6015\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sales over time - Example\n",
    "df.set_index('date', inplace=True) \n",
    "df['sellingprice'].resample('M').sum().plot()  # Monthly sales\n",
    "plt.show()\n",
    "\n",
    "# Popular vehicle models\n",
    "df['make'].value_counts().head(10).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Government"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ta-lib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
